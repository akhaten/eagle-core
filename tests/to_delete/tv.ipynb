{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "import eaglecore.utils\n",
    "import eaglecore.differential\n",
    "import eaglecore.thresholding\n",
    "import eaglecore.signal.processing\n",
    "\n",
    "def tv(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    lamda: float, \n",
    "    sigma: float, \n",
    "    nb_iterations: int,\n",
    "    tol: float = 0\n",
    ") -> numpy.ndarray:\n",
    "    \"\"\"Total Variation Regularization with Split Bregman\n",
    "    \"\"\"\n",
    "    \n",
    "    lap_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel = lasp.filters.linear.laplacian(),\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel=h,\n",
    "        shape_out=y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "\n",
    "\n",
    "    cst1 = h2_diag + sigma * lap_diag\n",
    "    cst2 = numpy.conj(h_diag) * numpy.fft.fft2(y)\n",
    "   \n",
    "\n",
    "    # INitialization\n",
    "    u = numpy.copy(y) \n",
    "    d_x=numpy.zeros_like(y)\n",
    "    d_y=numpy.zeros_like(y)\n",
    "    b_x=numpy.zeros_like(y)\n",
    "    b_y=numpy.zeros_like(y)\n",
    "\n",
    "    for i in range(1, nb_iterations+1):\n",
    "\n",
    "        a = sigma * (\n",
    "            eaglecore.differential.dxT(d_x-b_x)\n",
    "            + eaglecore.differential.dyT(d_y-b_y)\n",
    "        )\n",
    "\n",
    "        b = numpy.fft.fft2(a) + cst2\n",
    "\n",
    "        u0 = numpy.copy(u)\n",
    "        \n",
    "        u = numpy.real(numpy.fft.ifft2(b / cst1))\n",
    "\n",
    "        err = numpy.linalg.norm(u-u0, 'fro') \\\n",
    "            / numpy.linalg.norm(u, 'fro')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print('Iterations: {} ! \\t error is: {}'.format(i, err))\n",
    "\n",
    "        if err <= tol:\n",
    "            break\n",
    "\n",
    "        u_dx = eaglecore.differential.dx(u)\n",
    "        u_dy = eaglecore.differential.dy(u)\n",
    "\n",
    "        d_x, d_y = eaglecore.thresholding.multidimensional_soft(\n",
    "            numpy.array([u_dx+b_x, u_dy+b_y]),\n",
    "            lamda/sigma\n",
    "        )\n",
    "\n",
    "        b_x += (u_dx-d_x)\n",
    "        b_y += (u_dy-d_y)\n",
    "\n",
    "    u = eaglecore.signal.processing.normalize(\n",
    "        signal = u,\n",
    "        new_min = 0.0,\n",
    "        new_max = 1.0\n",
    "    )\n",
    "\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.fft\n",
    "import typing\n",
    "\n",
    "import eaglecore.thresholding\n",
    "\n",
    "def create_total_variation_step(\n",
    "    oper_dx: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dy: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dxT: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dyT: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    lamda: float, \n",
    "    sigma: float, \n",
    "    cst1: numpy.ndarray, \n",
    "    cst2: numpy.ndarray\n",
    ") -> typing.Callable[[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray], numpy.ndarray]:\n",
    "    \n",
    "    def total_variation_step(\n",
    "        d_x: numpy.ndarray, \n",
    "        d_y: numpy.ndarray, \n",
    "        b_x: numpy.ndarray, \n",
    "        b_y: numpy.ndarray \n",
    "    ) -> typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray]:\n",
    "    \n",
    "        a = sigma * ( oper_dxT(d_x-b_x) + oper_dyT(d_y-b_y) )\n",
    "\n",
    "        b = numpy.fft.fft2(a) + cst2\n",
    "        \n",
    "        u = numpy.real(numpy.fft.ifft2(b / cst1))\n",
    "\n",
    "        u_dx = oper_dx(u)\n",
    "        u_dy = oper_dy(u)\n",
    "\n",
    "        d_x, d_y = eaglecore.thresholding.multidimensional_soft(\n",
    "            numpy.array([u_dx + b_x, u_dy + b_y]),\n",
    "            lamda / sigma\n",
    "        )\n",
    "\n",
    "        b_x = b_x + (u_dx - d_x)\n",
    "        b_y = b_y + (u_dy - d_y)\n",
    "        \n",
    "        return u, d_x, d_y, b_x, b_y\n",
    "    \n",
    "    return total_variation_step\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eaglecore.utils\n",
    "import eaglecore.differential\n",
    "import eaglecore.thresholding\n",
    "import eaglecore.signal.processing\n",
    "import eaglecore.filters.linear\n",
    "\n",
    "def tv(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    lamda: float, \n",
    "    sigma: float, \n",
    "    nb_iterations: int,\n",
    "    tol: float = 0.0\n",
    ") -> numpy.ndarray:\n",
    "    \"\"\"Total Variation Regularization with Split Bregman\n",
    "    \"\"\"\n",
    "    \n",
    "    lap_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel = eaglecore.filters.linear.laplacian(),\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel=h,\n",
    "        shape_out=y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "    \n",
    "    cst1 = h2_diag + sigma * lap_diag\n",
    "    cst2 = numpy.conj(h_diag) * numpy.fft.fftn(y)\n",
    "    \n",
    "    tv_step = create_total_variation_step(\n",
    "        oper_dx = lambda arr : eaglecore.differential.dfc(arr, axis=0),\n",
    "        oper_dy = lambda arr : eaglecore.differential.dfc(arr, axis=1),\n",
    "        oper_dxT = lambda arr : eaglecore.differential.tdfc(arr, axis=0),\n",
    "        oper_dyT = lambda arr : eaglecore.differential.tdfc(arr, axis=1),\n",
    "        lamda = lamda,\n",
    "        sigma = sigma,\n",
    "        cst1 = cst1, cst2 = cst2 \n",
    "    )\n",
    "    \n",
    "    u0 = numpy.copy(y) \n",
    "    d_x = numpy.zeros_like(y)\n",
    "    d_y = numpy.zeros_like(y)\n",
    "    b_x = numpy.zeros_like(y)\n",
    "    b_y = numpy.zeros_like(y)\n",
    "      \n",
    "    for i in range(1, nb_iterations+1):\n",
    "        \n",
    "        u, d_x, d_y, b_x, b_y = tv_step(d_x, d_y, b_x, b_y)\n",
    "        \n",
    "        err = numpy.linalg.norm(u-u0, 'fro') \\\n",
    "            / numpy.linalg.norm(u, 'fro')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print('Iterations: {} ! \\t error is: {}'.format(i, err))\n",
    "\n",
    "        if err <= tol:\n",
    "            break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TupleArray3 = typing.Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray]\n",
    "\n",
    "def create_total_variation_step_v2(\n",
    "    oper_dx: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dy: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dxT: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    oper_dyT: typing.Callable[[numpy.ndarray], numpy.ndarray], \n",
    "    lamda: float, \n",
    "    sigma: float, \n",
    "    cst1: numpy.ndarray, \n",
    "    cst2: numpy.ndarray\n",
    ") -> typing.Callable[[numpy.ndarray, numpy.ndarray], TupleArray3] :\n",
    "    \n",
    "    def total_variation_step(\n",
    "        d: numpy.ndarray, # (2, N, M)\n",
    "        b: numpy.ndarray, # (2, N, M)\n",
    "    ) -> TupleArray3:\n",
    "    \n",
    "        calc1 = sigma * ( oper_dxT(d[0]-b[0]) + oper_dyT(d[1]-b[1]) ) # (N, M)\n",
    "\n",
    "        calc2 = numpy.fft.fftn(calc1) + cst2 # (N, M)\n",
    "        \n",
    "        u = numpy.real(numpy.fft.ifftn(calc2 / cst1)) # (N, M)\n",
    "\n",
    "        grad_u = numpy.array([ oper_dx(u), oper_dy(u) ]) # (2, N, M)\n",
    "\n",
    "        d_next = eaglecore.thresholding.multidimensional_soft(\n",
    "            grad_u + b,\n",
    "            lamda / sigma\n",
    "        ) # (2, N, M)\n",
    "\n",
    "        b_next = b + (grad_u - d_next) # (2, N, M)\n",
    "        \n",
    "        return u, d_next, b_next\n",
    "    \n",
    "    return total_variation_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eaglecore.utils\n",
    "import eaglecore.differential\n",
    "import eaglecore.thresholding\n",
    "import eaglecore.signal.processing\n",
    "import eaglecore.filters.linear\n",
    "\n",
    "def tv(\n",
    "    y: numpy.ndarray, \n",
    "    h: numpy.ndarray, \n",
    "    lamda: float, \n",
    "    sigma: float, \n",
    "    nb_iterations: int,\n",
    "    tol: float = 0.0\n",
    ") -> numpy.ndarray:\n",
    "    \"\"\"Total Variation Regularization with Split Bregman\n",
    "    \"\"\"\n",
    "    \n",
    "    lap_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel = eaglecore.filters.linear.laplacian(),\n",
    "        shape_out = y.shape\n",
    "    )\n",
    "\n",
    "    h_diag = eaglecore.utils.fourier_diagonalization(\n",
    "        kernel=h,\n",
    "        shape_out=y.shape\n",
    "    )\n",
    "\n",
    "    h2_diag = numpy.abs(h_diag)**2\n",
    "    \n",
    "    cst1 = h2_diag + sigma * lap_diag\n",
    "    cst2 = numpy.conj(h_diag) * numpy.fft.fftn(y)\n",
    "    \n",
    "    tv_step = create_total_variation_step_v2(\n",
    "        oper_dx = lambda arr : eaglecore.differential.dfc(arr, axis=0),\n",
    "        oper_dy = lambda arr : eaglecore.differential.dfc(arr, axis=1),\n",
    "        oper_dxT = lambda arr : eaglecore.differential.tdfc(arr, axis=0),\n",
    "        oper_dyT = lambda arr : eaglecore.differential.tdfc(arr, axis=1),\n",
    "        lamda = lamda,\n",
    "        sigma = sigma,\n",
    "        cst1 = cst1, cst2 = cst2 \n",
    "    )\n",
    "    \n",
    "    u0 = numpy.copy(y) \n",
    "    d = numpy.zeros(shape = (2, y.shape[0], y.shape[1]))\n",
    "    b = numpy.zeros(shape = (2, y.shape[0], y.shape[1]))\n",
    "      \n",
    "    for i in range(1, nb_iterations+1):\n",
    "        \n",
    "        u, d, b = tv_step(d, b)\n",
    "        \n",
    "        err = numpy.linalg.norm(u-u0, 'fro') \\\n",
    "            / numpy.linalg.norm(u, 'fro')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            print('Iterations: {} ! \\t error is: {}'.format(i, err))\n",
    "\n",
    "        if err <= tol:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 7.08279084+0.j        ,  0.43138919-1.1758553j ,\n",
       "          0.8446633 +0.j        ,  0.43138919+1.1758553j ],\n",
       "        [ 0.12303442-1.0233237j , -0.43570235+0.10248436j,\n",
       "          1.0492727 -0.73071561j,  0.62312533+0.93014696j],\n",
       "        [ 1.84549884+0.j        ,  0.85553356-0.72168894j,\n",
       "         -0.55092788+0.j        ,  0.85553356+0.72168894j],\n",
       "        [ 0.12303442+1.0233237j ,  0.62312533-0.93014696j,\n",
       "          1.0492727 +0.73071561j, -0.43570235-0.10248436j]],\n",
       "\n",
       "       [[ 8.54692116+0.j        , -0.52058224-0.8556335j ,\n",
       "          0.74436953+0.j        , -0.52058224+0.8556335j ],\n",
       "        [-1.06042451+1.06288015j, -0.2455616 +0.33623352j,\n",
       "         -0.11632324+1.01479391j,  0.05700076-0.53954572j],\n",
       "        [-0.14718493+0.j        ,  0.08751988+0.36348709j,\n",
       "          1.97991891+0.j        ,  0.08751988-0.36348709j],\n",
       "        [-1.06042451-1.06288015j,  0.05700076+0.53954572j,\n",
       "         -0.11632324-1.01479391j, -0.2455616 -0.33623352j]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy.fft\n",
    "\n",
    "\n",
    "arr = numpy.random.rand(2, 4, 4)\n",
    "arr\n",
    "\n",
    "arr_fft_ = numpy.array(\n",
    "    [numpy.fft.fft2(arr[0]), numpy.fft.fft2(arr[1])]\n",
    ")\n",
    "arr_fft_\n",
    "\n",
    "arr_fft = numpy.fft.fft2(arr, axes=[1, 2])\n",
    "arr_fft\n",
    "\n",
    "numpy.fft.fftn(arr, axes = [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : 2.4 5.76\n",
      "Iteration 100 : 4.888886343202771e-10 2.3901209676754565e-19\n",
      "Iteration 200 : 9.95883736531439e-20 9.917844166878207e-39\n",
      "Iteration 300 : 2.0286509995609565e-29 4.115424878019668e-58\n",
      "Iteration 400 : 4.132435069532589e-39 1.7077019603902814e-77\n",
      "Iteration 500 : 8.417918906504187e-49 7.086135871648064e-97\n",
      "Iteration 600 : 1.7147603658415285e-58 2.940403112260973e-116\n",
      "Iteration 700 : 3.4930285560116794e-68 1.2201248493113037e-135\n",
      "Iteration 800 : 7.11542483495949e-78 5.062927058195828e-155\n",
      "Iteration 900 : 1.4494376375716342e-87 2.10086946520924e-174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3621235240738185e-193"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x: float) -> float:\n",
    "    return x**2\n",
    "\n",
    "def df(x: float) -> float:\n",
    "    return 2*x\n",
    "\n",
    "def minimize_f(start: float, nb_epochs: int, learning_rate: float, verbose: int) -> float:\n",
    "    \n",
    "    x = start\n",
    "    for no_epoch in range(0, nb_epochs):\n",
    "        x = x - learning_rate * df(x)\n",
    "        if(nb_epochs % verbose == 0):\n",
    "            print('Epoch {} :'.format(no_epoch), x, f(x))\n",
    "    \n",
    "    return f(x)\n",
    "\n",
    "minimize_f(start = 3, nb_epochs = 1000, learning_rate = 0.1, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : 111114.11111111111 8.999757006560823e-06\n",
      "Iteration 100 : 111114.11921067319 8.999756350531769e-06\n",
      "Iteration 200 : 111114.12731023415 8.9997556945029e-06\n",
      "Iteration 300 : 111114.13540979379 8.999755038474234e-06\n",
      "Iteration 400 : 111114.14350935219 8.999754382445764e-06\n",
      "Iteration 500 : 111114.15160890947 8.999753726417481e-06\n",
      "Iteration 600 : 111114.15970846562 8.999753070389384e-06\n",
      "Iteration 700 : 111114.16780802066 8.999752414361474e-06\n",
      "Iteration 800 : 111114.17590757448 8.999751758333758e-06\n",
      "Iteration 900 : 111114.18400712695 8.999751102306248e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(111114.1920256828, 8.999750452839194e-06)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x: float) -> float:\n",
    "    return 1 / x\n",
    "\n",
    "def df(x: float) -> float:\n",
    "    return -1 / (x**2)\n",
    "\n",
    "def minimize_f(start: float, nb_iters: int, learning_rate: float, verbose: int) -> float:\n",
    "    \n",
    "    x = start\n",
    "    for i in range(0, nb_iters):\n",
    "        x = x - learning_rate * df(x)\n",
    "        if(i % verbose == 0):\n",
    "            print('Iteration {} :'.format(i), x, f(x))\n",
    "    \n",
    "    return x, f(x)\n",
    "\n",
    "minimize_f(start = 3, nb_iters = 1000, learning_rate = 1_000_000, verbose=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
